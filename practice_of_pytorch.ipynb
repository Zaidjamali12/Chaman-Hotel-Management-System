{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f84386f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.16606862843036652\n",
      "Epoch 40, Loss: 0.04921847954392433\n",
      "Epoch 60, Loss: 0.04377974569797516\n",
      "Epoch 80, Loss: 0.03975312411785126\n",
      "Epoch 100, Loss: 0.03610431030392647\n",
      "Trained weight: 1.7798343896865845\n",
      "Trained bias: 0.500461995601654\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Data\n",
    "x = torch.tensor([1., 2., 3.])\n",
    "y_true = torch.tensor([2., 4., 6.])\n",
    "\n",
    "# Parameters\n",
    "w = torch.tensor(0.5, requires_grad=True)\n",
    "b = torch.tensor(0.1, requires_grad=True)\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.01\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    # 1️⃣ Forward pass: compute prediction\n",
    "    y_pred = w * x + b\n",
    "    \n",
    "    # 2️⃣ Compute loss (Mean Squared Error)\n",
    "    loss = torch.mean((y_pred - y_true) ** 2)\n",
    "    \n",
    "    # 3️⃣ Backward pass: compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # 4️⃣ Update weights manually\n",
    "    with torch.no_grad():  # disable gradient tracking during update\n",
    "        w -= lr * w.grad\n",
    "        b -= lr * b.grad\n",
    "        \n",
    "    \n",
    "    # 5️⃣ Zero gradients for next iteration\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "    # Print loss every 20 epochs\n",
    "    if (epoch+1) % 20 == 0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "print(\"Trained weight:\", w.item())\n",
    "print(\"Trained bias:\", b.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b21f27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "data type of scaler : torch.int64\n",
      "data type of vector : torch.int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "scaler=torch.tensor(0.1, dtype=torch.int64)\n",
    "print(scaler)\n",
    "\n",
    "# scaler  which have single value\n",
    "#vector which have multiple value\n",
    "# list which have multiple value and different data type\n",
    "# tensor which have multiple value and same data type and more efficient than list\n",
    "\n",
    "vector=torch.tensor([2,4])\n",
    "\n",
    "scaler.ndim\n",
    "vector.ndim # ndim tell the dimesional of given tensor\n",
    "\n",
    "\n",
    "scaler.item() # item() only work for single value tensor\n",
    "\n",
    "# some basic concept :\n",
    "print(\"data type of scaler :\",scaler.dtype)\n",
    "print(\"data type of vector :\",vector.dtype)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2046016e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.08904146403074265\n",
      "Epoch 40, Loss: 0.07570742070674896\n",
      "Epoch 60, Loss: 0.06611595302820206\n",
      "Epoch 80, Loss: 0.0577394962310791\n",
      "Epoch 100, Loss: 0.05042418837547302\n",
      "Trained weight: 2.854706048965454\n",
      "Trained bias: 0.5245567560195923\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x=torch.tensor([1, 2, 3, 4, 5])\n",
    "y_true=torch.tensor([3, 6, 9, 12, 15])\n",
    "\n",
    "w=torch.tensor(0.5, requires_grad=True)\n",
    "b=torch.tensor(0.1, requires_grad=True)\n",
    "\n",
    "#forwad pass\n",
    "y_perdict=w*x + b\n",
    "\n",
    "# loss calculate \n",
    "loss=torch.mean((y_perdict - y_true)**2)\n",
    "\n",
    "learning_rate=0.01\n",
    "epochs=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # forward pass\n",
    "    y_perdict=w*x + b\n",
    "\n",
    "    # loss calculate \n",
    "    loss=torch.mean((y_perdict - y_true)**2)\n",
    "\n",
    "    # backward pass:\n",
    "    loss.backward()\n",
    "\n",
    "    #adjust weight and bias\n",
    "    with torch.no_grad():\n",
    "        w-=learning_rate * w.grad\n",
    "        b-=learning_rate * b.grad\n",
    "\n",
    "    # zero gradients\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "    if (epoch+1) % 20 ==0:\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "print(\"Trained weight:\", w.item())\n",
    "print(\"Trained bias:\", b.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4042c2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [2, 3, 4, 5]])\n",
      "tensor([[ 5,  8, 11, 14],\n",
      "        [ 8, 13, 18, 23],\n",
      "        [11, 18, 25, 32],\n",
      "        [14, 23, 32, 41]])\n",
      "tensor([[ 1,  4,  9, 16],\n",
      "        [ 4,  9, 16, 25]])\n",
      "tensor([[29, 39],\n",
      "        [39, 53]])\n"
     ]
    }
   ],
   "source": [
    "value_1=torch.tensor([[1,2],\n",
    "                      [2,3],\n",
    "                      [3,4],\n",
    "                      [4,5]])\n",
    "value_t=value_1.T\n",
    "print(value_t)\n",
    "multiplication=torch.matmul(value_1, value_1.T)\n",
    "print(multiplication)\n",
    "\n",
    "test=torch.tensor([[1, 2, 3, 4],\n",
    "        [2, 3, 4, 5]])\n",
    "\n",
    "multi=torch.multiply(test, test)\n",
    "print(multi)\n",
    "\n",
    "matrix_multi=torch.matmul(test, test.reshape(4,2))\n",
    "print(matrix_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03a2e141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.5000,  4.5000],\n",
      "          [ 2.5000,  6.5000],\n",
      "          [ 3.5000,  8.5000],\n",
      "          [ 4.5000, 10.5000]]]], grad_fn=<AddBackward0>)\n",
      "torch.Size([1, 1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor( [[[[1, 2],\n",
    "     [2, 3],\n",
    "     [3, 4],\n",
    "     [4, 5]]]])\n",
    "#its dimesinal[batch, channels, height, width] = [1, 1, 4, 2]\n",
    "\n",
    "y=torch.tensor( [8, 13, 18, 23])\n",
    "\n",
    "w=torch.tensor( [1.0, 2.0], requires_grad=True)\n",
    "b=torch.tensor(0.5, requires_grad=True)\n",
    "y_perdict=x*w +b\n",
    "print(y_perdict)\n",
    "\n",
    "print(x.size())\n",
    "\n",
    "#print(x[1]).. when we want to access specific element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a516f",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "tensor rendom is used in nural netwrok to impelemnt in random values and used in nural network it important topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47ecc51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.8236, 2.7149, 3.7474, 1.7408, 2.4027, 1.8963, 1.8735, 1.6603],\n",
       "        [2.7149, 3.2659, 3.6997, 1.9448, 2.7467, 1.5096, 2.1131, 1.5159],\n",
       "        [3.7474, 3.6997, 5.5126, 2.2819, 3.6274, 2.7303, 2.8956, 2.5139],\n",
       "        [1.7408, 1.9448, 2.2819, 2.4740, 1.8494, 1.6476, 1.4681, 1.2352],\n",
       "        [2.4027, 2.7467, 3.6274, 1.8494, 2.9184, 1.8221, 1.9948, 1.4948],\n",
       "        [1.8963, 1.5096, 2.7303, 1.6476, 1.8221, 2.1094, 1.3043, 1.4840],\n",
       "        [1.8735, 2.1131, 2.8956, 1.4681, 1.9948, 1.3043, 1.8717, 1.4679],\n",
       "        [1.6603, 1.5159, 2.5139, 1.2352, 1.4948, 1.4840, 1.4679, 1.4445]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor=torch.rand(8,9)\n",
    "random_tensor\n",
    "random_tensor.shape\n",
    "random_tensor.dtype\n",
    "random_tensor.ndim\n",
    "random_tensor @ random_tensor.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcdbe4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1]\n",
      "[[42.33333333]\n",
      " [87.66666667]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[40],[42],[45],[85],[88],[90]])\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "\n",
    "print(kmeans.labels_)      # cluster assignment\n",
    "print(kmeans.cluster_centers_)  # centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6890f109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 7462383616.0\n",
      "Epoch 40, Loss: 7326896128.0\n",
      "Epoch 60, Loss: 7325513728.0\n",
      "Epoch 80, Loss: 7325100544.0\n",
      "Epoch 100, Loss: 7324696576.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Input features (X)\n",
    "house_size = torch.tensor([33.,44.,55.,66.,77.,88.,99.,110.])\n",
    "number_rooms = torch.tensor([2.,3.,4.,5.,6.,7.,7.,16.])\n",
    "\n",
    "# Stack features -> shape (8, 2)\n",
    "X = torch.stack((house_size, number_rooms), dim=1)\n",
    "\n",
    "# Target (y)\n",
    "y_true = torch.tensor([150000.,190000.,100000.,122000.,10100.,10000.,210000.,220000.])\n",
    "\n",
    "# Initialize weights (2 inputs → 2 weights)\n",
    "W = torch.randn(2, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "learning_rate = 0.00001\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = X @ W + b      # (8,2) @ (2,) + b → (8,)\n",
    "\n",
    "    # Mean Squared Error Loss\n",
    "    loss = torch.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    with torch.no_grad():\n",
    "        W -= learning_rate * W.grad\n",
    "        b -= learning_rate * b.grad\n",
    "\n",
    "    # Zero gradients\n",
    "    W.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "    if (epoch + 1)%20  == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d084b625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output using vector = [ 2  6 20]\n",
      "output using scaler = 28\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, got input (8), mat (8x3), vec (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m output\u001b[38;5;241m=\u001b[39mw\u001b[38;5;241m*\u001b[39mEngine_Size \u001b[38;5;241m+\u001b[39m w\u001b[38;5;241m*\u001b[39mHorsepower \u001b[38;5;241m+\u001b[39m w\u001b[38;5;241m*\u001b[39mCar_Age \u001b[38;5;241m+\u001b[39m b\n\u001b[0;32m     16\u001b[0m x\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mstack((Engine_Size, Horsepower, Car_Age), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m outputs\u001b[38;5;241m=\u001b[39m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241m+\u001b[39m b\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(outputs)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, got input (8), mat (8x3), vec (1)"
     ]
    }
   ],
   "source": [
    "y=np.array([2,3,4])\n",
    "z=np.array([1,2,5])\n",
    "# main difference between vector and scaler multiplication\n",
    "# vector(y*z) give output multiplication\n",
    "#scaler give real life output(Y@z)\n",
    "print(\"output using vector =\",y*z)\n",
    "print(\"output using scaler =\",y@z)\n",
    "\n",
    "Engine_Size=torch.tensor([1000, 1500, 1800, 2000, 2500, 3000, 3500, 4000])\n",
    "Horsepower=torch.tensor([70,   90,   110,  130,  160,  200,  250,  300])\n",
    "Car_Age=torch.tensor([10,   8,    6,    5,    4,    3,    2,    1])\n",
    "w=torch.tensor([0.5], requires_grad=True)\n",
    "b=torch.tensor(0.5, requires_grad=True)\n",
    "output=w*Engine_Size + w*Horsepower + w*Car_Age + b\n",
    "\n",
    "x=torch.stack((Engine_Size, Horsepower, Car_Age), dim=1)\n",
    "outputs=x @ w+ b\n",
    "print(outputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95aaa91",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "both arguments to matmul need to be at least 1D, but they are 0D and 2D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m#forword pass\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     x\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mstack((Engine_Size, Horsepower, Car_Age), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m     y_perdict\u001b[38;5;241m=\u001b[39m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m \u001b[38;5;241m+\u001b[39m b\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# find loss\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     loss\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmean((y_perdict \u001b[38;5;241m-\u001b[39m Price)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: both arguments to matmul need to be at least 1D, but they are 0D and 2D"
     ]
    }
   ],
   "source": [
    "# input features\n",
    "Engine_Size=torch.tensor([1000, 1500, 1800, 2000, 2500, 3000, 3500, 4000])\n",
    "Horsepower=torch.tensor([70,   90,   110,  130,  160,  200,  250,  300])\n",
    "Car_Age=torch.tensor([10,   8,    6,    5,    4,    3,    2,    1])\n",
    "\n",
    "#perdicted:\n",
    "Price=torch.tensor([5000, 7000, 9000, 11000, 15000, 20000, 28000, 35000])\n",
    "\n",
    "# first we intailize weight and bias\n",
    "w=torch.tensor(0.01, requires_grad=True)\n",
    "b=torch.tensor(0.1, requires_grad=True)\n",
    "\n",
    "# learning rate\n",
    "lr=0.0001\n",
    "epochs=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #forword pass\n",
    "    x=torch.stack((Engine_Size, Horsepower, Car_Age), dim=1)\n",
    "    y_perdict=w @ x + b\n",
    "\n",
    "    # find loss\n",
    "    loss=torch.mean((y_perdict - Price)**2)\n",
    "\n",
    "    #bacword pass:\n",
    "    loss.backward()\n",
    "\n",
    "    #adjust weight:\n",
    "    with torch.no_grad():\n",
    "        w-=lr * w.grad\n",
    "        b-=lr * b.grad\n",
    "\n",
    "    #gradient intialize zero:\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epochs ={epoch +1} , loss {loss}  \")\n",
    "\n",
    "    \n",
    "print(\"weight : \",w )\n",
    "print(\"Bias : \",b)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c870989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2ac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, Loss: 3330102.0\n",
      "Epoch 400, Loss: 2151992.5\n",
      "Epoch 600, Loss: 1448904.75\n",
      "Epoch 800, Loss: 996520.6875\n",
      "Epoch 1000, Loss: 705249.875\n",
      "\n",
      "Final Weights: tensor([4418.8936, 7359.3374, 1304.8568], requires_grad=True)\n",
      "Final Bias: tensor([16249.9766], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# -------------------------------\n",
    "# Input features\n",
    "# -------------------------------\n",
    "Engine_Size = torch.tensor([1000., 1500., 1800., 2000., 2500., 3000., 3500., 4000.])\n",
    "Horsepower  = torch.tensor([70.,   90.,   110.,  130.,  160.,  200.,  250.,  300.])\n",
    "Car_Age     = torch.tensor([10.,    8.,    6.,    5.,    4.,    3.,    2.,    1.])\n",
    "\n",
    "# Target\n",
    "Price = torch.tensor([5000., 7000., 9000., 11000., 15000., 20000., 28000., 35000.])\n",
    "\n",
    "# -------------------------------\n",
    "# Feature Scaling (Mean Normalization)\n",
    "# -------------------------------\n",
    "Engine_Size = (Engine_Size - Engine_Size.mean()) / Engine_Size.std()\n",
    "Horsepower  = (Horsepower  - Horsepower.mean())  / Horsepower.std()\n",
    "Car_Age     = (Car_Age     - Car_Age.mean())     / Car_Age.std()\n",
    "\n",
    "# -------------------------------\n",
    "# Stack features -> X matrix (8 x 3)\n",
    "# -------------------------------\n",
    "X = torch.stack((Engine_Size, Horsepower, Car_Age), dim=1)\n",
    "\n",
    "# -------------------------------\n",
    "# Initialize weights and bias\n",
    "# -------------------------------\n",
    "W = torch.randn(3, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "# -------------------------------\n",
    "# Training parameters\n",
    "# -------------------------------\n",
    "lr = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# -------------------------------\n",
    "# Training loop\n",
    "# -------------------------------\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = X @ W + b\n",
    "\n",
    "    # Mean Squared Error loss\n",
    "    loss = torch.mean((y_pred - Price) ** 2)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Gradient descent update\n",
    "    with torch.no_grad():\n",
    "        W -= lr * W.grad\n",
    "        b -= lr * b.grad\n",
    "\n",
    "    # Zero gradients\n",
    "    W.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Final parameters\n",
    "# -------------------------------\n",
    "\n",
    "print(\"\\nFinal Weights:\", W)\n",
    "print(\"Final Bias:\", b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa61d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 200 , lost : 24895644.0\n",
      "Epochs 400 , lost : 15510846.0\n",
      "Epochs 600 , lost : 10632452.0\n",
      "Epochs 800 , lost : 7551273.5\n",
      "Epochs 1000 , lost : 5567382.5\n",
      "final weight  tensor([18036.2500,  1281.9674, 18221.6797,  1262.9478], requires_grad=True)\n",
      "Final bias  tensor([67249.8125], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#input Features\n",
    "year_experience = torch.tensor([1,2,3,5,7,10,12,15], dtype=torch.float32).unsqueeze(1)  # (8,1)\n",
    "Education_level = torch.tensor([1,1,2,2,2,3,3,3], dtype=torch.float32).unsqueeze(1)\n",
    "Age             = torch.tensor([22,24,26,30,34,40,45,50], dtype=torch.float32).unsqueeze(1)\n",
    "skill_score     = torch.tensor([5,6,6,7,8,8,9,9], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "\n",
    "#perdicted:\n",
    "Target=torch.tensor([25000, 30000, 38000, 50000, 65000, 90000, 110000, 130000])\n",
    "\n",
    "#feature scalling:\n",
    "year_experience = (year_experience - year_experience.mean()) / year_experience.std()\n",
    "Education_level = (Education_level - Education_level.mean()) / Education_level.std()\n",
    "Age = (Age - Age.mean()) / Age.std()\n",
    "skill_score = (skill_score - skill_score.mean()) / skill_score.std()\n",
    "\n",
    "\n",
    "#stacking:\n",
    "X = torch.cat((year_experience, Education_level, Age, skill_score), dim=1)\n",
    "\n",
    "#intalize weight:\n",
    "W=torch.rand(4 , requires_grad=True)\n",
    "b=torch.rand(1, requires_grad=True)\n",
    "\n",
    "#intialize :\n",
    "lr=0.001\n",
    "epochs=1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #forward pass:\n",
    "    Perdict = X @ W + b  \n",
    "\n",
    "    # loss perduction:\n",
    "    loss=torch.mean(Perdict - Target)**2\n",
    "\n",
    "    #backward pass:\n",
    "    loss.backward()\n",
    "\n",
    "    # weight Adjust:\n",
    "    with torch.no_grad():\n",
    "        W-=lr * W.grad\n",
    "        b-=lr * b.grad\n",
    "\n",
    "    # zero gradient:\n",
    "    W.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "    if(epoch+1)%200==0:\n",
    "        print(f\"Epochs {epoch+1} , lost : {loss}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"final weight \",W)\n",
    "print(\"Final bias \",b)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e728bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200, Loss: nan\n",
      "Epoch 400, Loss: nan\n",
      "Epoch 600, Loss: nan\n",
      "Epoch 800, Loss: nan\n",
      "Epoch 1000, Loss: nan\n",
      "Weights: tensor([[nan, nan, nan, nan]])\n",
      "Bias: tensor([nan])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Data\n",
    "X = torch.tensor(\n",
    "[\n",
    " [1,  1, 22, 5],\n",
    " [2,  1, 24, 6],\n",
    " [3,  2, 26, 6],\n",
    " [5,  2, 30, 7],\n",
    " [7,  2, 34, 8],\n",
    " [10, 3, 40, 8],\n",
    " [12, 3, 45, 9],\n",
    " [15, 3, 50, 9]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "y = torch.tensor(\n",
    "[2500, 3000, 3800, 5000, 6500, 9000, 11000, 13000],\n",
    "dtype=torch.float32\n",
    ")\n",
    "\n",
    "# Simple Linear Layer (no class)\n",
    "model = nn.Linear(4, 1)\n",
    "\n",
    "# Loss & Optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    y_pred = model(X).squeeze()\n",
    "\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.2f}\")\n",
    "\n",
    "# Final Weights & Bias\n",
    "print(\"Weights:\", model.weight.data)\n",
    "print(\"Bias:\", model.bias.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2efdd3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch , 100  , loss  : 70551968.000\n",
      "epoch , 200  , loss  : 49972820.000\n",
      "epoch , 300  , loss  : 36241996.000\n",
      "epoch , 400  , loss  : 27072792.000\n",
      "epoch , 500  , loss  : 20945264.000\n",
      "epoch , 600  , loss  : 16847780.000\n",
      "epoch , 700  , loss  : 14106187.000\n",
      "epoch , 800  , loss  : 12270849.000\n",
      "epoch , 900  , loss  : 11041559.000\n",
      "epoch , 1000  , loss  : 10217816.000\n",
      "Weight :  tensor([ 277.1129,  757.8405, 1212.3589], requires_grad=True)\n",
      "Bias  :  tensor([8173.6885], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# input features\n",
    "Year_of_experiment=torch.tensor([21,34,12,20,13,15],dtype=torch.float32)\n",
    "Age=torch.tensor([23,43,22,11,23,41],dtype=torch.float32)\n",
    "Education_level=torch.tensor([1,1,2,2,2,3],dtype=torch.float32)\n",
    "\n",
    "# stacking of inputs\n",
    "X=torch.stack([Year_of_experiment,Age,Education_level],dim=1)\n",
    "\n",
    "#SCALLING:\n",
    "X=(X-X.mean(dim=0))/ X.std(dim=0)\n",
    "\n",
    "#perdict value\n",
    "y_target=torch.tensor([2000,12000,10030, 10070,10600,12000],dtype=torch.float32)\n",
    "\n",
    "#intialize weight\n",
    "w=torch.rand(3, requires_grad=True)\n",
    "b=torch.rand(1,requires_grad=True)\n",
    "\n",
    "lr=0.001\n",
    "epochs=1000\n",
    "lembda=0.5\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #farward pass data\n",
    "    y_perdict=X @ w +b\n",
    "\n",
    "    #loss calculate:\n",
    "    loss=torch.mean((y_perdict - y_target)**2)\n",
    "\n",
    "\n",
    "    loss_regulization=loss + lembda * torch.sum(w**2)\n",
    "\n",
    "\n",
    "    #take data backward:\n",
    "    loss_regulization.backward()\n",
    "\n",
    "    #update learning rate:\n",
    "    with torch.no_grad():\n",
    "        w-=lr *w.grad\n",
    "        b-=lr *b.grad\n",
    "\n",
    "    \n",
    "    #take gradient zero:\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    \n",
    "    if (epoch+1)%100==0:\n",
    "        print(f\"epoch , {epoch+1}  , loss  : {loss_regulization.item():.3f}\")\n",
    "\n",
    "print(\"Weight : \",w)\n",
    "print(\"Bias  : \",b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3243b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Features (5 samples, 2 features)\n",
    "X = torch.tensor([\n",
    "    [2.0, 1.0],\n",
    "    [3.0, 2.0],\n",
    "    [4.0, 3.0],\n",
    "    [5.0, 3.0],\n",
    "    [6.0, 4.0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Labels (0 = Fail, 1 = Pass)\n",
    "y_true = torch.tensor([0, 0, 0, 1, 1], dtype=torch.float32)\n",
    "\n",
    "#intialize weight :\n",
    "w=torch.rand(2,1, requires_grad=True)\n",
    "b=torch.rand(1,requires_grad=True)\n",
    "lr=0.1\n",
    "epochs=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #farward pass \n",
    "    y_pred=torch.sigmoid(X @ w + b)\n",
    "\n",
    "    #binary loss\n",
    "    binary_loss = -torch.mean(-y_true* torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred) )\n",
    "    print(binary_loss)\n",
    "\n",
    "    #backward pass:\n",
    "    binary_loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w -=w - lr * w.grad\n",
    "        b -=b - lr * b.grad\n",
    "\n",
    "    # make gradient zero:\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "    if (epoch+ 1)==0:\n",
    "        print(f\" Epoch {epoch +1} , loss {loss}\")\n",
    "\n",
    "print(\"WEight \",w)\n",
    "print('bias',b)   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c0336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Features (5 samples, 2 features)\n",
    "X = torch.tensor([\n",
    "    [2.0, 1.0],\n",
    "    [3.0, 2.0],\n",
    "    [4.0, 3.0],\n",
    "    [5.0, 3.0],\n",
    "    [6.0, 4.0]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Labels (0 = Fail, 1 = Pass)\n",
    "y_true = torch.tensor([0, 0, 0, 1, 1], dtype=torch.float32)\n",
    "\n",
    "#intialize weight :\n",
    "w=torch.rand(2,1, requires_grad=True)\n",
    "b=torch.rand(1,requires_grad=True)\n",
    "lr=0.1\n",
    "epochs=1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #farward pass \n",
    "    y_pred=torch.sigmoid(X @ w + b)\n",
    "\n",
    "    #binary loss\n",
    "    binary_loss = -torch.mean(-y_true* torch.log(y_pred) + (1 - y_true) * torch.log(1 - y_pred) )\n",
    "    print(binary_loss)\n",
    "\n",
    "    #backward pass:\n",
    "    binary_loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        w -=w - lr * w.grad\n",
    "        b -=b - lr * b.grad\n",
    "\n",
    "    # make gradient zero:\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "    if (epoch+ 1)%100==0:\n",
    "        print(f\" Epoch {epoch +1} , loss {loss}\")\n",
    "\n",
    "print(\"WEight \",w)\n",
    "print('bias',b)   \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7922ba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Probabilities:\n",
      " tensor([[0.5001],\n",
      "        [0.5001],\n",
      "        [0.5001],\n",
      "        [0.5002],\n",
      "        [0.5002]])\n",
      "Predicted Class:\n",
      " tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "Accuracy: 300.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Data\n",
    "study_hours = torch.tensor([2, 4, 5, 6, 7], dtype=torch.float32)\n",
    "sleep_hours = torch.tensor([7, 6, 6, 5, 4], dtype=torch.float32)\n",
    "X = torch.stack((study_hours, sleep_hours), dim=1)\n",
    "y_true = torch.tensor([0, 0, 1, 1, 1], dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Trained weights and bias\n",
    "W = torch.tensor([[0.0001 , 0.000009]], dtype=torch.float32)  # fill your W\n",
    "b = torch.tensor([0], dtype=torch.float32)         # fill your b\n",
    "\n",
    "# Forward pass\n",
    "y_pred = torch.sigmoid(X @ W.T + b)\n",
    "\n",
    "# Convert to class\n",
    "y_class = (y_pred >= 0.5).float()\n",
    "\n",
    "# Accuracy\n",
    "accuracy = (y_class == y_true).sum() / y_true.shape[0] * 100\n",
    "\n",
    "# Print\n",
    "print(\"Predicted Probabilities:\\n\", y_pred)\n",
    "print(\"Predicted Class:\\n\", y_class)\n",
    "print(f\"Accuracy: {accuracy.item():.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47d65bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([1,2,3,4,5,6,7,8])\n",
    "print(a.shape)\n",
    "\n",
    "b=a.view(1,-1)\n",
    "print(b)\n",
    "\n",
    "c=a.view(4,2)\n",
    "print(c)\n",
    "\n",
    "\n",
    "d=a.view(2,4)\n",
    "print(d)\n",
    "\n",
    "y_true = torch.tensor([0,0,1,1,1], dtype=torch.float32).view(-1,1)\n",
    "print(y_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "653da2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.22.99\n"
     ]
    }
   ],
   "source": [
    "import dlib\n",
    "print(dlib.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6f20d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
